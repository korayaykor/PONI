import numpy as np
from math import pi
#from baseline_utils import convert_insseg_to_sseg
import habitat
import habitat_sim
from build_map_utils import semantic_map
#from habitat.tasks.utils import cartesian_to_polar
#from habitat.utils.geometry_utils import quaternion_rotate_vector
from poni.default import get_config
import quaternion
import os  # Added missing import for os module

# specify on which scene you want to build the map
scene = '2t7WUuJeko7'
height = 0.16325

# using 8 angles is most efficient
theta_lst = [0, pi / 4, pi / 2, pi * 3. / 4,
             pi, pi * 5. / 4, pi * 3. / 2, pi * 7. / 4]


# ============================= initialize a grid =========================================
cfg = get_config()  
#x = np.arange(-config.SEM_MAP, config.SEM_MAP.WORLD_SIZE, 0.3)
x = np.arange(-cfg.SEM_MAP.WORLD_SIZE, cfg.SEM_MAP.WORLD_SIZE, 0.3)
z = np.arange(-cfg.SEM_MAP.WORLD_SIZE, cfg.SEM_MAP.WORLD_SIZE, 0.3)
xv, zv = np.meshgrid(x, z)
grid_H, grid_W = zv.shape

print("build a semantic map on scene = kfPV7w3FaU5")

# =============================== initialize the habitat environment ============================
config = habitat.get_config(
    config_paths='../configs/habitat_env/build_map_mp3d.yaml')
config.defrost()
config.SIMULATOR.SCENE = "../data/scene_datasets/hm3d_uncompressed/00000-kfPV7w3FaU5/kfPV7w3FaU5.basis.glb"
config.SIMULATOR.SCENE_DATASET = "../data/hm3d_annotated_basis.scene_dataset_config.json'"
config.freeze()

env = habitat.sims.make_sim(config.SIMULATOR.TYPE, config=config.SIMULATOR)
env.reset()

# ============================ get scene ins to cat dict =================================
scene_semantics = env.semantic_annotations()
ins2cat_dict = {
    int(obj.id.split("_")[-1]): obj.category.index() for obj in scene_semantics.objects}

# ================================ Building a map ===============================
sem_map = semantic_map("output")

count_ = 0

# These functions were improperly indented - fixed by moving them to the module level
def cartesian_to_polar(x, y):
    rho = np.sqrt(x**2 + y**2)
    phi = np.arctan2(y, x)
    return rho, phi

def quaternion_rotate_vector(
    quat: quaternion.quaternion, v: np.ndarray
        ) -> np.ndarray:
            r"""Rotates a vector by a quaternion
            Args:
                quaternion: The quaternion to rotate by
                v: The vector to rotate
            Returns:
                np.ndarray: The rotated vector
            """
            vq = quaternion.quaternion(0, 0, 0, 0)
            vq.imag = v
            return (quat * vq * quat.inverse()).imag

def create_folder(folder_name, clean_up=False):
    """ create folder with directory folder_name.

    If the folder exists before creation, setup clean_up to True to remove files in the folder.
    """
    flag_exist = os.path.isdir(folder_name)
    if not flag_exist:
        print('{} folder does not exist, so create one.'.format(folder_name))
        os.makedirs(folder_name)
    else:
        print('{} folder already exists, so do nothing.'.format(folder_name))
        if clean_up:
            os.system('rm {}/*.png'.format(folder_name))
            os.system('rm {}/*.npy'.format(folder_name))
            os.system('rm {}/*.jpg'.format(folder_name))

def convert_insseg_to_sseg(insseg, ins2cat_dict):
    """
    convert instance segmentation image InsSeg (generated by Habitat Simulator) into Semantic segmentation image SSeg,
    given the mapping from instance to category ins2cat_dict.
    """
    ins_id_list = list(ins2cat_dict.keys())
    sseg = np.zeros(insseg.shape, dtype=np.int16)
    for ins_id in ins_id_list:
        sseg = np.where(insseg == ins_id, ins2cat_dict[ins_id], sseg)
    return sseg


# ========================= generate observations ===========================
for grid_z in range(grid_H):
    for grid_x in range(grid_W):
        x = xv[grid_z, grid_x]
        z = zv[grid_z, grid_x]
        y = height
        agent_pos = np.array([x, y, z])

        flag_nav = env.is_navigable(agent_pos)

        if flag_nav:
            # ==================== traverse theta ======================
            for idx_theta, theta in enumerate(theta_lst):
                agent_rot = habitat_sim.utils.common.quat_from_angle_axis(
                    theta, habitat_sim.geo.GRAVITY)
                observations = env.get_observations_at(
                    agent_pos, agent_rot, keep_agent_at_new_pose=True)
                rgb_img = observations['rgb']
                depth_img = observations['depth'][:, :, 0]
                insseg_img = observations['semantic']
                # convert instance segmentation to semantic segmentation
                sseg_img = convert_insseg_to_sseg(insseg_img, ins2cat_dict)

                # =============================== get agent global pose on habitat env ========================#
                agent_pos = env.get_agent_state().position
                agent_rot = env.get_agent_state().rotation
                heading_vector = quaternion_rotate_vector(
                    agent_rot.inverse(), np.array([0, 0, -1]))
                phi = cartesian_to_polar(
                    -heading_vector[2], heading_vector[0])[1]
                angle = phi
                print(f'agent position = {agent_pos}, angle = {angle}')
                pose = (agent_pos[0], agent_pos[2], angle)

                sem_map.build_semantic_map(
                    rgb_img, depth_img, sseg_img, pose, count_)
                count_ += 1

sem_map.save_final_map()

env.close()