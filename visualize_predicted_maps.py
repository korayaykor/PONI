#!/usr/bin/env python3
"""
Script to load and visualize predicted semantic maps generated by PONI's neural network.

This script demonstrates how to:
1. Load saved semantic maps from HDF5 files
2. Visualize different map channels (obstacle, explored, semantic categories)
3. Create comparison visualizations
4. Extract statistics from the maps

Usage:
    python visualize_predicted_maps.py --map_file ./predicted_maps/final_semantic_map.h5
    python visualize_predicted_maps.py --map_dir ./predicted_maps --create_animation
"""

import argparse
import os
import numpy as np
import h5py
import json
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from PIL import Image
import glob


def load_semantic_map(file_path):
    """
    Load semantic map from HDF5 file.
    
    Args:
        file_path: Path to HDF5 file
        
    Returns:
        data: Dictionary containing map data and metadata
    """
    data = {}
    
    with h5py.File(file_path, 'r') as f:
        # Load all datasets
        for key in f.keys():
            if key == 'metadata':
                data['metadata'] = {}
                meta_group = f['metadata']
                # Load attributes
                for attr_key in meta_group.attrs.keys():
                    data['metadata'][attr_key] = meta_group.attrs[attr_key]
                # Load datasets in metadata group
                for dataset_key in meta_group.keys():
                    data['metadata'][dataset_key] = np.array(meta_group[dataset_key])
            else:
                data[key] = np.array(f[key])
    
    return data


def visualize_map_channels(map_data, save_dir=None):
    """
    Create visualizations for different map channels.
    
    Args:
        map_data: Dictionary containing map data
        save_dir: Directory to save visualizations
    """
    if 'full_map' in map_data:
        full_map = map_data['full_map']
        
        # Extract different channels
        obstacle_map = full_map[0]  # Channel 0: Obstacles
        explored_map = full_map[1]  # Channel 1: Explored areas
        agent_map = full_map[2]     # Channel 2: Current agent location
        past_map = full_map[3]      # Channel 3: Past agent locations
        semantic_maps = full_map[4:] # Channels 4+: Semantic categories
        
    else:
        # Individual maps
        obstacle_map = map_data.get('obstacle_map', np.zeros((100, 100)))
        explored_map = map_data.get('explored_map', np.zeros((100, 100)))
        agent_map = map_data.get('agent_map', np.zeros((100, 100)))
        past_map = map_data.get('past_locations_map', np.zeros((100, 100)))
        semantic_maps = map_data.get('semantic_map', np.zeros((21, 100, 100)))
    
    # Create a comprehensive visualization
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('PONI Predicted Semantic Map Visualization', fontsize=16)
    
    # 1. Obstacle map
    im1 = axes[0, 0].imshow(obstacle_map, cmap='Reds', vmin=0, vmax=1)
    axes[0, 0].set_title('Obstacle Map')
    axes[0, 0].set_xlabel('X (pixels)')
    axes[0, 0].set_ylabel('Y (pixels)')
    plt.colorbar(im1, ax=axes[0, 0], shrink=0.8)
    
    # 2. Explored areas
    im2 = axes[0, 1].imshow(explored_map, cmap='Greens', vmin=0, vmax=1)
    axes[0, 1].set_title('Explored Areas')
    axes[0, 1].set_xlabel('X (pixels)')
    axes[0, 1].set_ylabel('Y (pixels)')
    plt.colorbar(im2, ax=axes[0, 1], shrink=0.8)
    
    # 3. Agent trajectory
    trajectory_map = agent_map + past_map * 0.5
    im3 = axes[0, 2].imshow(trajectory_map, cmap='Blues', vmin=0, vmax=1)
    axes[0, 2].set_title('Agent Trajectory\n(Current + Past Locations)')
    axes[0, 2].set_xlabel('X (pixels)')
    axes[0, 2].set_ylabel('Y (pixels)')
    plt.colorbar(im3, ax=axes[0, 2], shrink=0.8)
    
    # 4. Combined navigation map
    nav_map = np.zeros((*obstacle_map.shape, 3))
    nav_map[:, :, 0] = obstacle_map  # Red for obstacles
    nav_map[:, :, 1] = explored_map  # Green for explored
    nav_map[:, :, 2] = trajectory_map  # Blue for trajectory
    axes[1, 0].imshow(nav_map)
    axes[1, 0].set_title('Combined Navigation Map\n(R:Obstacles, G:Explored, B:Trajectory)')
    axes[1, 0].set_xlabel('X (pixels)')
    axes[1, 0].set_ylabel('Y (pixels)')
    
    # 5. Semantic categories (sum across all categories)
    semantic_sum = np.sum(semantic_maps, axis=0)
    im5 = axes[1, 1].imshow(semantic_sum, cmap='viridis', vmin=0, vmax=semantic_sum.max())
    axes[1, 1].set_title('Total Semantic Predictions\n(Sum across all categories)')
    axes[1, 1].set_xlabel('X (pixels)')
    axes[1, 1].set_ylabel('Y (pixels)')
    plt.colorbar(im5, ax=axes[1, 1], shrink=0.8)
    
    # 6. Dominant semantic category
    dominant_category = np.argmax(semantic_maps, axis=0)
    # Mask areas with no semantic predictions
    semantic_mask = semantic_sum > 0.1
    dominant_category_masked = np.where(semantic_mask, dominant_category, -1)
    
    im6 = axes[1, 2].imshow(dominant_category_masked, cmap='tab20', vmin=-1, vmax=20)
    axes[1, 2].set_title('Dominant Semantic Category\n(Argmax across categories)')
    axes[1, 2].set_xlabel('X (pixels)')
    axes[1, 2].set_ylabel('Y (pixels)')
    plt.colorbar(im6, ax=axes[1, 2], shrink=0.8)
    
    plt.tight_layout()
    
    if save_dir:
        save_path = os.path.join(save_dir, 'map_channels_visualization.png')
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"Map channels visualization saved to: {save_path}")
    
    plt.show()
    
    return fig


def analyze_semantic_categories(semantic_maps, save_dir=None):
    """
    Analyze and visualize individual semantic categories.
    
    Args:
        semantic_maps: Array of shape (num_categories, H, W)
        save_dir: Directory to save analysis
    """
    num_categories, H, W = semantic_maps.shape
    
    # Calculate statistics for each category
    category_stats = []
    for i in range(num_categories):
        cat_map = semantic_maps[i]
        total_prediction = cat_map.sum()
        max_confidence = cat_map.max()
        mean_confidence = cat_map.mean()
        pixels_with_prediction = (cat_map > 0.1).sum()
        
        category_stats.append({
            'category_id': i,
            'total_prediction': total_prediction,
            'max_confidence': max_confidence,
            'mean_confidence': mean_confidence,
            'pixels_with_prediction': pixels_with_prediction,
            'percentage_coverage': 100 * pixels_with_prediction / (H * W)
        })
    
    # Sort by total prediction strength
    category_stats.sort(key=lambda x: x['total_prediction'], reverse=True)
    
    # Print top categories
    print("\nTop Semantic Categories (by total prediction strength):")
    print("-" * 80)
    print(f"{'Rank':<4} {'Cat ID':<6} {'Total':<10} {'Max':<8} {'Mean':<8} {'Pixels':<8} {'Coverage %':<10}")
    print("-" * 80)
    
    for rank, stats in enumerate(category_stats[:10], 1):
        print(f"{rank:<4} {stats['category_id']:<6} {stats['total_prediction']:<10.2f} "
              f"{stats['max_confidence']:<8.3f} {stats['mean_confidence']:<8.5f} "
              f"{stats['pixels_with_prediction']:<8} {stats['percentage_coverage']:<10.2f}")
    
    # Visualize top categories
    top_categories = category_stats[:6]  # Show top 6
    
    if len(top_categories) > 0:
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('Top Predicted Semantic Categories', fontsize=16)
        
        axes = axes.flatten()
        
        for i, stats in enumerate(top_categories):
            cat_id = stats['category_id']
            cat_map = semantic_maps[cat_id]
            
            im = axes[i].imshow(cat_map, cmap='hot', vmin=0, vmax=cat_map.max())
            axes[i].set_title(f'Category {cat_id}\n'
                            f'Max: {stats["max_confidence"]:.3f}, '
                            f'Coverage: {stats["percentage_coverage"]:.1f}%')
            axes[i].set_xlabel('X (pixels)')
            axes[i].set_ylabel('Y (pixels)')
            plt.colorbar(im, ax=axes[i], shrink=0.8)
        
        plt.tight_layout()
        
        if save_dir:
            save_path = os.path.join(save_dir, 'top_semantic_categories.png')
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"Top semantic categories visualization saved to: {save_path}")
        
        plt.show()
    
    return category_stats


def create_time_series_animation(map_dir, save_dir=None):
    """
    Create an animation showing the evolution of semantic maps over time.
    
    Args:
        map_dir: Directory containing sequential map files
        save_dir: Directory to save animation
    """
    # Find all map files in chronological order
    map_files = sorted(glob.glob(os.path.join(map_dir, "semantic_map_step_*.h5")))
    
    if len(map_files) == 0:
        print(f"No sequential map files found in {map_dir}")
        return
    
    print(f"Found {len(map_files)} map files for animation")
    
    # Load all maps
    maps_data = []
    for file_path in map_files:
        data = load_semantic_map(file_path)
        maps_data.append(data)
    
    # Create animation
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    fig.suptitle('PONI Semantic Mapping Evolution Over Time', fontsize=16)
    
    # Initialize plots
    im1 = axes[0].imshow(np.zeros((100, 100)), cmap='Greens', vmin=0, vmax=1)
    axes[0].set_title('Explored Areas')
    axes[0].set_xlabel('X (pixels)')
    axes[0].set_ylabel('Y (pixels)')
    
    im2 = axes[1].imshow(np.zeros((100, 100)), cmap='Reds', vmin=0, vmax=1)
    axes[1].set_title('Obstacles')
    axes[1].set_xlabel('X (pixels)')
    axes[1].set_ylabel('Y (pixels)')
    
    im3 = axes[2].imshow(np.zeros((100, 100)), cmap='viridis', vmin=0, vmax=1)
    axes[2].set_title('Semantic Predictions (Sum)')
    axes[2].set_xlabel('X (pixels)')
    axes[2].set_ylabel('Y (pixels)')
    
    step_text = fig.text(0.5, 0.02, '', ha='center', fontsize=14)
    
    def animate(frame):
        data = maps_data[frame]
        
        if 'full_map' in data:
            explored_map = data['full_map'][1]
            obstacle_map = data['full_map'][0]
            semantic_maps = data['full_map'][4:]
        else:
            explored_map = data.get('explored_map', np.zeros((100, 100)))
            obstacle_map = data.get('obstacle_map', np.zeros((100, 100)))
            semantic_maps = data.get('semantic_map', np.zeros((21, 100, 100)))
        
        semantic_sum = np.sum(semantic_maps, axis=0)
        
        im1.set_array(explored_map)
        im2.set_array(obstacle_map)
        im3.set_array(semantic_sum)
        im3.set_clim(vmin=0, vmax=semantic_sum.max())
        
        step_text.set_text(f'Step: {frame + 1}/{len(maps_data)}')
        
        return [im1, im2, im3, step_text]
    
    # Create animation
    anim = animation.FuncAnimation(fig, animate, frames=len(maps_data), 
                                  interval=500, blit=False, repeat=True)
    
    if save_dir:
        save_path = os.path.join(save_dir, 'semantic_mapping_evolution.gif')
        anim.save(save_path, writer='pillow', fps=2)
        print(f"Animation saved to: {save_path}")
    
    plt.show()
    
    return anim


def main():
    parser = argparse.ArgumentParser(description="Visualize predicted semantic maps from PONI")
    parser.add_argument("--map_file", type=str, help="Path to specific map file to visualize")
    parser.add_argument("--map_dir", type=str, help="Directory containing map files")
    parser.add_argument("--save_dir", type=str, default="./visualizations", help="Directory to save visualizations")
    parser.add_argument("--create_animation", action="store_true", help="Create animation from sequential maps")
    parser.add_argument("--analyze_categories", action="store_true", default=True, help="Analyze semantic categories")
    
    args = parser.parse_args()
    
    # Create save directory
    os.makedirs(args.save_dir, exist_ok=True)
    
    if args.map_file:
        # Visualize specific map file
        print(f"Loading map from: {args.map_file}")
        
        if not os.path.exists(args.map_file):
            print(f"Error: File {args.map_file} does not exist")
            return
        
        # Load the map
        map_data = load_semantic_map(args.map_file)
        
        # Print metadata if available
        if 'metadata' in map_data:
            print("\nMap Metadata:")
            for key, value in map_data['metadata'].items():
                print(f"  {key}: {value}")
        
        # Visualize map channels
        print("\nVisualizing map channels...")
        visualize_map_channels(map_data, args.save_dir)
        
        # Analyze semantic categories
        if args.analyze_categories:
            if 'semantic_map' in map_data:
                print("\nAnalyzing semantic categories...")
                analyze_semantic_categories(map_data['semantic_map'], args.save_dir)
            elif 'full_map' in map_data and len(map_data['full_map']) > 4:
                print("\nAnalyzing semantic categories...")
                analyze_semantic_categories(map_data['full_map'][4:], args.save_dir)
    
    elif args.map_dir:
        # Work with directory of maps
        if not os.path.exists(args.map_dir):
            print(f"Error: Directory {args.map_dir} does not exist")
            return
        
        if args.create_animation:
            print(f"Creating animation from maps in: {args.map_dir}")
            create_time_series_animation(args.map_dir, args.save_dir)
        
        # Also visualize final map if available
        final_map_path = os.path.join(args.map_dir, "final_semantic_map.h5")
        if os.path.exists(final_map_path):
            print(f"\nLoading final map from: {final_map_path}")
            map_data = load_semantic_map(final_map_path)
            
            print("Visualizing final map channels...")
            visualize_map_channels(map_data, args.save_dir)
            
            if args.analyze_categories:
                if 'semantic_map' in map_data:
                    print("Analyzing final semantic categories...")
                    analyze_semantic_categories(map_data['semantic_map'], args.save_dir)
        
        # Load and print summary if available
        summary_path = os.path.join(args.map_dir, "experiment_summary.json")
        if os.path.exists(summary_path):
            with open(summary_path, 'r') as f:
                summary = json.load(f)
            
            print("\nExperiment Summary:")
            print(f"  Total steps: {summary['experiment']['num_steps']}")
            print(f"  Final pose: x={summary['final_pose']['x']:.3f}m, "
                  f"y={summary['final_pose']['y']:.3f}m, "
                  f"theta={summary['final_pose']['theta']:.3f}rad")
            print(f"  Explored area: {summary['map_stats']['explored_percentage']:.1f}%")
            print(f"  Semantic coverage: {summary['map_stats']['semantic_percentage']:.1f}%")
    
    else:
        print("Please specify either --map_file or --map_dir")
        return
    
    print(f"\nVisualization complete! Check {args.save_dir} for saved images.")


if __name__ == "__main__":
    main()
